#
# Licensed to the Apache Software Foundation (ASF) under one or more
# contributor license agreements.  See the NOTICE file distributed with
# this work for additional information regarding copyright ownership.
# The ASF licenses this file to You under the Apache License, Version 2.0
# (the "License"); you may not use this file except in compliance with
# the License.  You may obtain a copy of the License at
#
#    http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
#

# Default system properties included when running spark-submit.
# This is useful for setting default environmental settings.

# Example:
# spark.master                     spark://master:7077
# spark.eventLog.enabled           true
# spark.eventLog.dir               hdfs://namenode:8021/directory
# spark.serializer                 org.apache.spark.serializer.KryoSerializer
# spark.driver.memory              5g
# spark.executor.extraJavaOptions  -XX:+PrintGCDetails -Dkey=value -Dnumbers="one two three"

# With this, Spark setup completes with Yarn. Now letâ€™s try to run sample job that comes with Spark binary distribution.
spark.master yarn

spark.yarn.jars hdfs://localhost:9000/spark/share/lib/*.jar

spark.driver.memory 512m
spark.yarn.am.memory 512m
spark.executor.memory 512m

# 1. Configure history server
spark.history.provider org.apache.spark.deploy.history.FsHistoryProvider
spark.history.fs.update.interval 10s
spark.history.ui.port 18080

# spark.eventLog.dir is the base directory in which Spark events are logged, if spark.eventLog.enabled is true. Within this base directory, Spark creates a sub-directory for each application, and logs the events specific to the application in this directory. Users may want to set this to a unified location like an HDFS directory so history files can be read by the history server.
spark.eventLog.enabled   true  
spark.eventLog.compress  true

spark.eventLog.dir hdfs://localhost:9000/spark/event-logs
spark.yarn.access.hadoopFileSystems hdfs://localhost:9000

# spark.history.fs.logDirectory is for the filesystem history provider, the URL to the directory containing application event logs to load. This can be a local file:// path, an HDFS path hdfs://namenode/shared/spark-logs or that of an alternative filesystem supported by the Hadoop APIs.

spark.history.fs.logDirectory hdfs://localhost:9000/spark/event-logs

# Kerberos
spark.acls.enable true
spark.admin.acls yarn,tallada
# spark.admin.acls.groups hadoop

spark.ui.view.acls yarn,tallada
spark.ui.view.acls.groups hadoop

spark.modify.acls yarn,spark,tallada
spark.modify.acls.groups hadoop

spark.history.kerberos.enabled   true
spark.history.kerberos.principal spark/localhost@EXAMPLE.COM
spark.history.kerberos.keytab    /var/keytabs/spark.keytab
history.server.spnego.kerberos.principal HTTP/_HOST@EXAMPLE.COM
history.server.spnego.keytab.file /var/keytabs/spark.keytab
spark.history.ui.acls.enable true 
spark.history.ui.admin.acls yarn,spark
spark.shuffle.service.enabled true

# YARN
# spark.master yarn
# WARN security.HadoopDelegationTokenManager: spark.yarn.security.tokens.hive.enabled is deprecated.  Please use spark.security.credentials.hive.enabled instead.

# spark.yarn.security.tokens.hive.enabled true

spark.security.credentials.hive.enabled true
spark.security.credentials.hbase.enabled true
spark.yarn.historyServer.allowTracking true

# 2021-06-21 07:30:08,883 WARN spark.SparkConf: The configuration key 'spark.yarn.principal' has been deprecated as of Spark 3.0 and may be removed in the future. Please use the new key 'spark.kerberos.principal' instead.
# 2021-06-21 07:30:09,044 WARN spark.SparkConf: The configuration key 'spark.yarn.keytab' has been deprecated as of Spark 3.0 and may be removed in the future. Please use the new key 'spark.kerberos.keytab' instead.
# spark.yarn.principal yarn/localhost@EXAMPLE.COM
# spark.yarn.keytab /var/keytabs/yarn.keytab

# spark.kerberos.principal spark/localhost@EXAMPLE.COM
# spark.kerberos.keytab /var/keytabs/spark.keytab

# spark.yarn.historyServer.address {{spark_history_server_host}}:{{spark_history_ui_port}}
spark.yarn.historyServer.address http://localhost:8188

# Enable spark and hive coupling 
# Link of interes: https://community.cloudera.com/t5/Community-Articles/Integrating-Apache-Hive-with-Apache-Spark-Hive-Warehouse/ta-p/249035

# spark.hadoop.hive.llap.daemon.service.hosts @llap0
spark.sql.hive.convertMetastoreOrc true
spark.sql.hive.hiveserver2.jdbc.url jdbc:hive2://localhost:10000
spark.datasource.hive.warehouse.load.staging.dir /tmp
spark.datasource.hive.warehouse.metastoreUri thrift://localhost:9083
spark.security.credentials.hiveserver2.enabled true 
spark.sql.hive.hiveserver2.jdbc.url.principal spark/_HOST@EXAMPLE.COM
spark.sql.hive.hiveserver2.jdbc.url.keytab /var/keytabs/spark.keytab

hive.server2.authentication.kerberos.principal spark/_HOST@EXAMPLE.COM
hive.server2.authentication.kerberos.keytab /var/keytabs/spark.keytab
spark.serializer org.apache.spark.serializer.KryoSerializer

# Configure hive-site.xml: https://cwiki.apache.org//confluence/display/Hive/Hive+on+Spark:+Getting+Started
